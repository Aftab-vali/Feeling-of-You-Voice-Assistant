<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Feeling of You - Voice Assistant Chat</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f0f0f0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
        }
        .container {
            text-align: center;
        }
        #message-box {
            width: 100%;
            height: 50px;
            margin-top: 20px;
            border-radius: 5px;
            padding: 10px;
        }
        button {
            padding: 10px 20px;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        button:hover {
            background-color: #45a049;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Feeling of You</h1>
        <button onclick="startRecognition()">Speak to Assistant</button>
        <input type="text" id="message-box" placeholder="Your message will appear here..." readonly />
        <div id="response-box"></div>
    </div>

    <script>
        // Initialize SpeechRecognition API
        const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.lang = 'en-US';
        recognition.interimResults = false;

        let isSpeaking = false; // Track whether the assistant is currently speaking
        let currentUtterance = null; // Store the current speech utterance

        // Function to stop current speech
        function stopSpeech() {
            if (isSpeaking && currentUtterance) {
                currentUtterance.onend = null; // Remove the onend listener
                speechSynthesis.cancel(); // Stop ongoing speech
                isSpeaking = false;
            }
        }

        // Function to handle the Speak to Assistant button
        function startRecognition() {
            stopSpeech(); // Stop any ongoing speech
            recognition.start(); // Start listening
        }

        // Handle speech recognition results
        recognition.onresult = async (event) => {
            const userMessage = event.results[0][0].transcript;
            document.getElementById('message-box').value = userMessage;

            // Send the user's voice message to the Flask server
            const response = await fetch('/chat', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ message: userMessage }),
            });

            const data = await response.json();
            const botResponse = data.response;

            document.getElementById('response-box').innerText = botResponse;

            // Speak the bot's response
            speak(botResponse);
        };

        recognition.onerror = (event) => {
            console.error('Speech recognition error:', event.error);
        };

        // Function to speak the response
        function speak(text) {
            stopSpeech(); // Stop any ongoing speech before starting a new one

            currentUtterance = new SpeechSynthesisUtterance(text);
            currentUtterance.lang = 'en-US';

            currentUtterance.onstart = () => {
                isSpeaking = true;
            };

            currentUtterance.onend = () => {
                isSpeaking = false;
                currentUtterance = null; // Clear the current utterance
            };

            speechSynthesis.speak(currentUtterance);
        }
    </script>
</body>
</html>
